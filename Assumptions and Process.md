# Assumptions and Thought Process

This document encompasses the assumptions that were made about the programming task and the thought process that was followed to implement the solution.

## Assumptions

Starting with the assumptions, the following points were considered while implementing the log file parser:

* The log file is a text file that contains log entries in the following format:
  ```
  <IP Address> - <Username> [<Date>] "<Request Method> <Request URL> <Request Protocol>" <Response Code> <Response Size> "<Referrer>" "<User Agent>"
  ```
  The assumption is that the log file is in this format and that each log entry is on a new line. Noting that the username is not always present in the log entries, and may be a hyphen (`-`) when not present.
* The log file may contain a large number of log entries, and the parser should be able to handle large log files efficiently. Even though the sample log file provided is small, the parser has been designed to handle larger log files.
* The log file parser is not intended to be a full-fledged log analysis tool, but rather a simple tool that can provide some basic statistics about the log file.
* The log file parser is designed to run on the Node.js runtime, and has been built using Typescript to take advantage of its type system and modern JavaScript features.
* The log file parser will only be used to parse Nginx access log files, and is not intended to be a generic log file parser that can parse any log file format.
* The statistics that the log file parser provides are as specified in the task description, in the implementation there have been slight modifications made to allow for different numbers of active IPs and top URLs to be displayed. The default values are 3 for both. The implementation has been done in such a way that this can be easily be extended, but that is not intended as an immediate feature.
* The log file parser will be extended in the future, but after more feature requests have been assessed, prioritized and agreed upon.
* The assumption has been made that the log files will be rotated eventually and that the parser only needs to handle the most recent log file. This means that files will be somewhat limited in size.

## Thought Process

The thought process that was followed to implement the log file parser is as follows:
* I initially started by drawing out the requirements from the task description and the sample log file provided. This helped me understand what the log file parser needed to do and what statistics it needed to provide.
  * The requirements were:
    * Parse an Nginx access log file.
    * Provide the number of unique IP addresses in the log file.
    * Provide the most active IP addresses in the log file. (Assuming this means the IP addresses that appear most frequently in the log file.)
    * Provide the most requested URLs in the log file. (Assuming this means the URLs that are requested most frequently in the log file.)
* I then started by creating a new Typescript project and setting up the project structure. I created the necessary directories and files, and set up the project to use Typescript. I also set up linting and formatting tools to ensure code quality.
* Furthermore, I understood from the assumptions and the task description that this would be a CLI tool, so while setting up the project, I also set up the bin file and the necessary configurations to make the project a CLI tool in the package.json file.
* Thinking about things that I would need to do and packages that I had used in the past to create similar CLI tools, I chose to use the `commander` package to handle the CLI arguments and options. This package is very easy to use and provides a lot of functionality out of the box for reading CLI arguments and options, and displaying help messages. Additionally, I used the `chalk` package to add some color to the output of the log file parser.
* With the project setup and the initial ideas in place I started to implement the log file parser in the following steps: (calling out here that I implemented Unit tests as I went, but I will not call out each test in the following steps)
  * Create an index.ts file that would be the entry point of the CLI tool.
  * Implement a Parser class that would be responsible for keeping the state of the application. The thought of a class here was so that I could pass the class scope around and keep the state of the application in one place, while keeping things tidier than a global state, or passing around a lot of variables.
  * Implement the run method in the Parser class that would read the log file, parse it, and output the statistics. This method would be called from the index.ts file. As I implemented this method I only tackled one of the steps at a time.
  * Implement the init method as this was required for getting the CLI arguments and options, importantly the file path to the log file.
  * Implement a FileStream class that would be responsible for reading the log file in a streaming fashion. This class would emit events when a new log entry was read, and the Parser class would listen for these events and process the log entries. This was done to ensure that the log file parser could handle large log files efficiently. It is worth noting here that this is a relatively simple class and in the Parsers current form it could be merged into the Parser class, but I chose to keep it separate for readability and to allow for future extension.
  * Implement the parseData method in the Parser class that would parse a log entry and extract the IP address and URL from it. This method would be called for each log entry read from the log file. As part of implementing this method I also implemented the Log class to represent a log entry. This would handle the parsing of the log entry and provide methods to extract the IP address and URL from it. Additionally, the Log class would be able to get a timestamp from the log entry, which was not required for the task, but could be useful in the future. I chose the implement the timestamp functionality as a method on this class that is not called in the initial setup, as it is not required for the task, and would negatively impact performance.
  * With these classes and parsed data in place I could begin to implement the statistics that needed to be output. I started implementing stand-alone calculator function that would take the parsed data and calculate the statistics (e.g. one function for unique IPs, one for active IPs, and one for top URLs). These functions would be called from the run method in the Parser class. When I finished implementing these functions however I began to simplify these functions by gathering common functionality between them and moving the logic for the specific statistic that we want to gather into the run method. This was done to reduce the need to have multiple functions performing similar tasks. It is worth calling out here that the CLI tool could be made more efficient by calculating these statistics all in a single loop through the log entries, but I chose to keep the code more readable and maintainable by separating the logic into separate function calls for each statistic.
  * Initially I was simply logging the statistics to the console, but as I thought about the functionality of standard CLI tools and reviewed the options that I had in the commander init method, I decided that I could implement a display output method that would take the statistics and display them in a more readable format. This method would be called from the run method in the Parser class. It also allows for a single place to manage disabling output when the silent flag is passed.
  * While I had been testing these functions in isolation with the default options as I went I then began testing to ensure that the CLI tool worked together as expected. Upon doing this I found that the parsing of the CLI options when updating the number of active IPs and top URLs was not working as expected, parsing numbers was fine but I wanted the option to disable calculating statistics for these too if possible. I updated the init method to handle this better and in the process simplified the code for handling the parsing of an option that could be a number of a boolean. As part of this I also removed the magic number 3 from the code and hoisted it to the top of the file as a const, however it may be better in the Parser as a single place to manage the default valuse, but for now it is kept in the init method as it is only used there.
    * Worth calling out here too that the init method now exports two function, one for init and one for processOption, this is important to call out as the tests for the init method do not mock the processOption function, making them more leaning towards integration tests than unit tests, but this was a trade off I was willing to make for the sake of simplicity, as the processOption function is very simple and overall the init method would not be very useful to test while mocking the processOption function.
  * I started writing integration tests then to ensure that the output was as expected based on options passed, this will help with confidence in the future when extending the tool.

Additionally, when I was confident in the CLI tool, I also implemented GitHub actions and an NPM package name to allow for publishing the tool. This was done to ensure that the tool could be easily installed and used by others. I also added a README.md file to the project to provide instructions on how to install and use the log file parser.